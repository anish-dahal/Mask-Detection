{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from LoadDataset.utils import (\n",
    "    MaskDetectionDataSet,\n",
    "    dataset_split,\n",
    "    dataloader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x164ce05e110>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaskDetectionDataSet(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with_mask', 'without_mask']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = dataset_split(dataset, val_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader(train_ds, batch_size=16, shuffle=True)\n",
    "valid_dl = dataloader(valid_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for img, labels in train_dl:\n",
    "    print(img.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning using pre-trained ResNet34 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskModel(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained = True):\n",
    "        super().__init__()\n",
    "        # use pretrained model\n",
    "        self.network = models.resnet34(pretrained=pretrained)\n",
    "        # Replace Last layer\n",
    "        self.network.fc = nn.Linear(self.network.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskModel(len(dataset.classes), pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [16, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [16, 64, 16, 16]             128\n",
      "              ReLU-3           [16, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [16, 64, 8, 8]               0\n",
      "            Conv2d-5             [16, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6             [16, 64, 8, 8]             128\n",
      "              ReLU-7             [16, 64, 8, 8]               0\n",
      "            Conv2d-8             [16, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [16, 64, 8, 8]             128\n",
      "             ReLU-10             [16, 64, 8, 8]               0\n",
      "       BasicBlock-11             [16, 64, 8, 8]               0\n",
      "           Conv2d-12             [16, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-13             [16, 64, 8, 8]             128\n",
      "             ReLU-14             [16, 64, 8, 8]               0\n",
      "           Conv2d-15             [16, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-16             [16, 64, 8, 8]             128\n",
      "             ReLU-17             [16, 64, 8, 8]               0\n",
      "       BasicBlock-18             [16, 64, 8, 8]               0\n",
      "           Conv2d-19             [16, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-20             [16, 64, 8, 8]             128\n",
      "             ReLU-21             [16, 64, 8, 8]               0\n",
      "           Conv2d-22             [16, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-23             [16, 64, 8, 8]             128\n",
      "             ReLU-24             [16, 64, 8, 8]               0\n",
      "       BasicBlock-25             [16, 64, 8, 8]               0\n",
      "           Conv2d-26            [16, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-27            [16, 128, 4, 4]             256\n",
      "             ReLU-28            [16, 128, 4, 4]               0\n",
      "           Conv2d-29            [16, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-30            [16, 128, 4, 4]             256\n",
      "           Conv2d-31            [16, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-32            [16, 128, 4, 4]             256\n",
      "             ReLU-33            [16, 128, 4, 4]               0\n",
      "       BasicBlock-34            [16, 128, 4, 4]               0\n",
      "           Conv2d-35            [16, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-36            [16, 128, 4, 4]             256\n",
      "             ReLU-37            [16, 128, 4, 4]               0\n",
      "           Conv2d-38            [16, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-39            [16, 128, 4, 4]             256\n",
      "             ReLU-40            [16, 128, 4, 4]               0\n",
      "       BasicBlock-41            [16, 128, 4, 4]               0\n",
      "           Conv2d-42            [16, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-43            [16, 128, 4, 4]             256\n",
      "             ReLU-44            [16, 128, 4, 4]               0\n",
      "           Conv2d-45            [16, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-46            [16, 128, 4, 4]             256\n",
      "             ReLU-47            [16, 128, 4, 4]               0\n",
      "       BasicBlock-48            [16, 128, 4, 4]               0\n",
      "           Conv2d-49            [16, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-50            [16, 128, 4, 4]             256\n",
      "             ReLU-51            [16, 128, 4, 4]               0\n",
      "           Conv2d-52            [16, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [16, 128, 4, 4]             256\n",
      "             ReLU-54            [16, 128, 4, 4]               0\n",
      "       BasicBlock-55            [16, 128, 4, 4]               0\n",
      "           Conv2d-56            [16, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-57            [16, 256, 2, 2]             512\n",
      "             ReLU-58            [16, 256, 2, 2]               0\n",
      "           Conv2d-59            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-60            [16, 256, 2, 2]             512\n",
      "           Conv2d-61            [16, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-62            [16, 256, 2, 2]             512\n",
      "             ReLU-63            [16, 256, 2, 2]               0\n",
      "       BasicBlock-64            [16, 256, 2, 2]               0\n",
      "           Conv2d-65            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-66            [16, 256, 2, 2]             512\n",
      "             ReLU-67            [16, 256, 2, 2]               0\n",
      "           Conv2d-68            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-69            [16, 256, 2, 2]             512\n",
      "             ReLU-70            [16, 256, 2, 2]               0\n",
      "       BasicBlock-71            [16, 256, 2, 2]               0\n",
      "           Conv2d-72            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-73            [16, 256, 2, 2]             512\n",
      "             ReLU-74            [16, 256, 2, 2]               0\n",
      "           Conv2d-75            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-76            [16, 256, 2, 2]             512\n",
      "             ReLU-77            [16, 256, 2, 2]               0\n",
      "       BasicBlock-78            [16, 256, 2, 2]               0\n",
      "           Conv2d-79            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-80            [16, 256, 2, 2]             512\n",
      "             ReLU-81            [16, 256, 2, 2]               0\n",
      "           Conv2d-82            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [16, 256, 2, 2]             512\n",
      "             ReLU-84            [16, 256, 2, 2]               0\n",
      "       BasicBlock-85            [16, 256, 2, 2]               0\n",
      "           Conv2d-86            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-87            [16, 256, 2, 2]             512\n",
      "             ReLU-88            [16, 256, 2, 2]               0\n",
      "           Conv2d-89            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-90            [16, 256, 2, 2]             512\n",
      "             ReLU-91            [16, 256, 2, 2]               0\n",
      "       BasicBlock-92            [16, 256, 2, 2]               0\n",
      "           Conv2d-93            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-94            [16, 256, 2, 2]             512\n",
      "             ReLU-95            [16, 256, 2, 2]               0\n",
      "           Conv2d-96            [16, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-97            [16, 256, 2, 2]             512\n",
      "             ReLU-98            [16, 256, 2, 2]               0\n",
      "       BasicBlock-99            [16, 256, 2, 2]               0\n",
      "          Conv2d-100            [16, 512, 1, 1]       1,179,648\n",
      "     BatchNorm2d-101            [16, 512, 1, 1]           1,024\n",
      "            ReLU-102            [16, 512, 1, 1]               0\n",
      "          Conv2d-103            [16, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-104            [16, 512, 1, 1]           1,024\n",
      "          Conv2d-105            [16, 512, 1, 1]         131,072\n",
      "     BatchNorm2d-106            [16, 512, 1, 1]           1,024\n",
      "            ReLU-107            [16, 512, 1, 1]               0\n",
      "      BasicBlock-108            [16, 512, 1, 1]               0\n",
      "          Conv2d-109            [16, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-110            [16, 512, 1, 1]           1,024\n",
      "            ReLU-111            [16, 512, 1, 1]               0\n",
      "          Conv2d-112            [16, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-113            [16, 512, 1, 1]           1,024\n",
      "            ReLU-114            [16, 512, 1, 1]               0\n",
      "      BasicBlock-115            [16, 512, 1, 1]               0\n",
      "          Conv2d-116            [16, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-117            [16, 512, 1, 1]           1,024\n",
      "            ReLU-118            [16, 512, 1, 1]               0\n",
      "          Conv2d-119            [16, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-120            [16, 512, 1, 1]           1,024\n",
      "            ReLU-121            [16, 512, 1, 1]               0\n",
      "      BasicBlock-122            [16, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-123            [16, 512, 1, 1]               0\n",
      "          Linear-124                    [16, 2]           1,026\n",
      "          ResNet-125                    [16, 2]               0\n",
      "================================================================\n",
      "Total params: 21,285,698\n",
      "Trainable params: 21,285,698\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 31.50\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 112.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.to(device), input_size=(3, 32, 32), batch_size = 16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function\n",
    "\n",
    "cross entroy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return torch.tensor(torch.sum(y_true==y_pred).item()/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 378/378 [03:57<00:00,  1.59it/s, train_accuracy=0.907, train_loss=0.257]\n",
      "100%|██████████| 95/95 [00:58<00:00,  1.64it/s, train_accuracy=0.907, train_loss=0.257, val_accuracy=0.921, val_loss=0.191]\n",
      "Epoch 2: 100%|██████████| 378/378 [03:23<00:00,  1.86it/s, train_accuracy=0.929, train_loss=0.197]\n",
      "100%|██████████| 95/95 [00:18<00:00,  5.07it/s, train_accuracy=0.929, train_loss=0.197, val_accuracy=0.861, val_loss=0.315]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "epoch = 2\n",
    "for i in range(epoch):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    train_loop = tqdm(train_dl, leave=True)\n",
    "    for x, labels in train_loop:\n",
    "        train_loop.set_description(f\"Epoch {i+1}\")\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x)\n",
    "        loss = loss_fn(y.float(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred =torch.max(y, dim = 1)\n",
    "        accuracy_val = accuracy(labels, pred)\n",
    "        train_loss.append(loss.item())\n",
    "        train_accuracy.append(accuracy_val.item())\n",
    "\n",
    "        train_loop.set_postfix(\n",
    "            train_loss=sum(train_loss) / len(train_loss),\n",
    "            train_accuracy=sum(train_accuracy) / len(train_accuracy),\n",
    "        )\n",
    "\n",
    "    val_loop = tqdm(valid_dl, leave=True)\n",
    "    with torch.no_grad():\n",
    "        for x, labels in val_loop:\n",
    "            y = model(x)\n",
    "            loss = loss_fn(y.float(), labels)\n",
    "\n",
    "            _, pred =torch.max(y, dim = 1)\n",
    "            accuracy_val = accuracy(labels, pred)\n",
    "            val_loss.append(loss.item())\n",
    "            val_accuracy.append(accuracy_val.item())\n",
    "\n",
    "            val_loop.set_postfix(\n",
    "                train_loss=sum(train_loss) / len(train_loss),\n",
    "                train_accuracy=sum(train_accuracy) / len(train_accuracy),\n",
    "                val_loss=sum(val_loss) / len(val_loss),\n",
    "                val_accuracy=sum(val_accuracy) / len(val_accuracy),\n",
    "            )\n",
    "\n",
    "    training_loss.append(sum(train_loss) / len(train_loss))\n",
    "    training_accuracy.append(sum(train_accuracy) / len(train_accuracy))\n",
    "    validation_loss.append(sum(val_loss) / len(val_loss))\n",
    "    validation_accuracy.append(sum(val_accuracy) / len(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
