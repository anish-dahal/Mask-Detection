{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from LoadDataset.utils import (\n",
    "    MaskDetectionDataSet,\n",
    "    dataset_split,\n",
    "    dataloader\n",
    ")\n",
    "from Model.ResNet import MaskModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1552cc800f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaskDetectionDataSet(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with_mask', 'without_mask']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = dataset_split(dataset, val_ratio = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dataloader(train_ds, batch_size=32, shuffle=True)\n",
    "valid_dl = dataloader(valid_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for img, labels in train_dl:\n",
    "    print(img.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Learning using pre-trained ResNet34 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskModel(len(dataset.classes), pretrained=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [32, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [32, 64, 112, 112]             128\n",
      "              ReLU-3         [32, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [32, 64, 56, 56]               0\n",
      "            Conv2d-5           [32, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [32, 64, 56, 56]             128\n",
      "              ReLU-7           [32, 64, 56, 56]               0\n",
      "            Conv2d-8           [32, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [32, 64, 56, 56]             128\n",
      "             ReLU-10           [32, 64, 56, 56]               0\n",
      "       BasicBlock-11           [32, 64, 56, 56]               0\n",
      "           Conv2d-12           [32, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [32, 64, 56, 56]             128\n",
      "             ReLU-14           [32, 64, 56, 56]               0\n",
      "           Conv2d-15           [32, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [32, 64, 56, 56]             128\n",
      "             ReLU-17           [32, 64, 56, 56]               0\n",
      "       BasicBlock-18           [32, 64, 56, 56]               0\n",
      "           Conv2d-19           [32, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [32, 64, 56, 56]             128\n",
      "             ReLU-21           [32, 64, 56, 56]               0\n",
      "           Conv2d-22           [32, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [32, 64, 56, 56]             128\n",
      "             ReLU-24           [32, 64, 56, 56]               0\n",
      "       BasicBlock-25           [32, 64, 56, 56]               0\n",
      "           Conv2d-26          [32, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [32, 128, 28, 28]             256\n",
      "             ReLU-28          [32, 128, 28, 28]               0\n",
      "           Conv2d-29          [32, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [32, 128, 28, 28]             256\n",
      "           Conv2d-31          [32, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [32, 128, 28, 28]             256\n",
      "             ReLU-33          [32, 128, 28, 28]               0\n",
      "       BasicBlock-34          [32, 128, 28, 28]               0\n",
      "           Conv2d-35          [32, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [32, 128, 28, 28]             256\n",
      "             ReLU-37          [32, 128, 28, 28]               0\n",
      "           Conv2d-38          [32, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [32, 128, 28, 28]             256\n",
      "             ReLU-40          [32, 128, 28, 28]               0\n",
      "       BasicBlock-41          [32, 128, 28, 28]               0\n",
      "           Conv2d-42          [32, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [32, 128, 28, 28]             256\n",
      "             ReLU-44          [32, 128, 28, 28]               0\n",
      "           Conv2d-45          [32, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [32, 128, 28, 28]             256\n",
      "             ReLU-47          [32, 128, 28, 28]               0\n",
      "       BasicBlock-48          [32, 128, 28, 28]               0\n",
      "           Conv2d-49          [32, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [32, 128, 28, 28]             256\n",
      "             ReLU-51          [32, 128, 28, 28]               0\n",
      "           Conv2d-52          [32, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [32, 128, 28, 28]             256\n",
      "             ReLU-54          [32, 128, 28, 28]               0\n",
      "       BasicBlock-55          [32, 128, 28, 28]               0\n",
      "           Conv2d-56          [32, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [32, 256, 14, 14]             512\n",
      "             ReLU-58          [32, 256, 14, 14]               0\n",
      "           Conv2d-59          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-60          [32, 256, 14, 14]             512\n",
      "           Conv2d-61          [32, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [32, 256, 14, 14]             512\n",
      "             ReLU-63          [32, 256, 14, 14]               0\n",
      "       BasicBlock-64          [32, 256, 14, 14]               0\n",
      "           Conv2d-65          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [32, 256, 14, 14]             512\n",
      "             ReLU-67          [32, 256, 14, 14]               0\n",
      "           Conv2d-68          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-69          [32, 256, 14, 14]             512\n",
      "             ReLU-70          [32, 256, 14, 14]               0\n",
      "       BasicBlock-71          [32, 256, 14, 14]               0\n",
      "           Conv2d-72          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [32, 256, 14, 14]             512\n",
      "             ReLU-74          [32, 256, 14, 14]               0\n",
      "           Conv2d-75          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [32, 256, 14, 14]             512\n",
      "             ReLU-77          [32, 256, 14, 14]               0\n",
      "       BasicBlock-78          [32, 256, 14, 14]               0\n",
      "           Conv2d-79          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [32, 256, 14, 14]             512\n",
      "             ReLU-81          [32, 256, 14, 14]               0\n",
      "           Conv2d-82          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [32, 256, 14, 14]             512\n",
      "             ReLU-84          [32, 256, 14, 14]               0\n",
      "       BasicBlock-85          [32, 256, 14, 14]               0\n",
      "           Conv2d-86          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [32, 256, 14, 14]             512\n",
      "             ReLU-88          [32, 256, 14, 14]               0\n",
      "           Conv2d-89          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [32, 256, 14, 14]             512\n",
      "             ReLU-91          [32, 256, 14, 14]               0\n",
      "       BasicBlock-92          [32, 256, 14, 14]               0\n",
      "           Conv2d-93          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [32, 256, 14, 14]             512\n",
      "             ReLU-95          [32, 256, 14, 14]               0\n",
      "           Conv2d-96          [32, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-97          [32, 256, 14, 14]             512\n",
      "             ReLU-98          [32, 256, 14, 14]               0\n",
      "       BasicBlock-99          [32, 256, 14, 14]               0\n",
      "          Conv2d-100            [32, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [32, 512, 7, 7]           1,024\n",
      "            ReLU-102            [32, 512, 7, 7]               0\n",
      "          Conv2d-103            [32, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-104            [32, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [32, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [32, 512, 7, 7]           1,024\n",
      "            ReLU-107            [32, 512, 7, 7]               0\n",
      "      BasicBlock-108            [32, 512, 7, 7]               0\n",
      "          Conv2d-109            [32, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [32, 512, 7, 7]           1,024\n",
      "            ReLU-111            [32, 512, 7, 7]               0\n",
      "          Conv2d-112            [32, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [32, 512, 7, 7]           1,024\n",
      "            ReLU-114            [32, 512, 7, 7]               0\n",
      "      BasicBlock-115            [32, 512, 7, 7]               0\n",
      "          Conv2d-116            [32, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [32, 512, 7, 7]           1,024\n",
      "            ReLU-118            [32, 512, 7, 7]               0\n",
      "          Conv2d-119            [32, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [32, 512, 7, 7]           1,024\n",
      "            ReLU-121            [32, 512, 7, 7]               0\n",
      "      BasicBlock-122            [32, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-123            [32, 512, 1, 1]               0\n",
      "          Linear-124                    [32, 2]           1,026\n",
      "          ResNet-125                    [32, 2]               0\n",
      "================================================================\n",
      "Total params: 21,285,698\n",
      "Trainable params: 21,285,698\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 18.38\n",
      "Forward/backward pass size (MB): 3081.00\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 3180.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.to(device), input_size=(3, 224, 224), batch_size = 32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function\n",
    "\n",
    "cross entroy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return torch.tensor(torch.sum(y_true==y_pred).item()/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 189/189 [13:03<00:00,  4.14s/it, train_accuracy=0.822, train_loss=0.483]\n",
      "100%|██████████| 48/48 [01:09<00:00,  1.45s/it, train_accuracy=0.822, train_loss=0.483, val_accuracy=0.872, val_loss=0.434]\n",
      "Epoch 2: 100%|██████████| 189/189 [13:25<00:00,  4.26s/it, train_accuracy=0.879, train_loss=0.43] \n",
      "100%|██████████| 48/48 [01:09<00:00,  1.45s/it, train_accuracy=0.879, train_loss=0.43, val_accuracy=0.898, val_loss=0.412]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "epoch = 2\n",
    "for i in range(epoch):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    train_loop = tqdm(train_dl, leave=True)\n",
    "    for x, labels in train_loop:\n",
    "        train_loop.set_description(f\"Epoch {i+1}\")\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x)\n",
    "        y = F.softmax(y)\n",
    "        loss = loss_fn(y.float(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred =torch.max(y, dim = 1)\n",
    "        accuracy_val = accuracy(labels, pred)\n",
    "        train_loss.append(loss.item())\n",
    "        train_accuracy.append(accuracy_val.item())\n",
    "\n",
    "        train_loop.set_postfix(\n",
    "            train_loss=sum(train_loss) / len(train_loss),\n",
    "            train_accuracy=sum(train_accuracy) / len(train_accuracy),\n",
    "        )\n",
    "\n",
    "    val_loop = tqdm(valid_dl, leave=True)\n",
    "    with torch.no_grad():\n",
    "        for x, labels in val_loop:\n",
    "            y = model(x)\n",
    "            y = F.softmax(y)\n",
    "            loss = loss_fn(y.float(), labels)\n",
    "\n",
    "            _, pred =torch.max(y, dim = 1)\n",
    "            accuracy_val = accuracy(labels, pred)\n",
    "            val_loss.append(loss.item())\n",
    "            val_accuracy.append(accuracy_val.item())\n",
    "\n",
    "            val_loop.set_postfix(\n",
    "                train_loss=sum(train_loss) / len(train_loss),\n",
    "                train_accuracy=sum(train_accuracy) / len(train_accuracy),\n",
    "                val_loss=sum(val_loss) / len(val_loss),\n",
    "                val_accuracy=sum(val_accuracy) / len(val_accuracy),\n",
    "            )\n",
    "\n",
    "    training_loss.append(sum(train_loss) / len(train_loss))\n",
    "    training_accuracy.append(sum(train_accuracy) / len(train_accuracy))\n",
    "    validation_loss.append(sum(val_loss) / len(val_loss))\n",
    "    validation_accuracy.append(sum(val_accuracy) / len(val_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
